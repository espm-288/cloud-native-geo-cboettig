[
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nThis course is based off of examples developed by Carl Boettiger with support of NASA TOPS funding, see Project Page.\nThis GitHub repository + notebook provides the real-time notes for our exploratory course, ESPM-288: Reproducible & Collaborative Data Science, which this year will focus on Cloud Native Geospatial Data in R & Python.\nThe website is built using quarto to render qmd and ipynb files, and is rendered and published automatically through GitHub Actions.\nUsers can use GitHub Codespaces to interactively run all files in the notebook for free and without installing any software."
  },
  {
    "objectID": "tutorials/example-6.html",
    "href": "tutorials/example-6.html",
    "title": "6: duckdb",
    "section": "",
    "text": "library(duckdbfs)\nlibrary(dplyr)\nlibrary(sf)\n\n\n# SQL\n\npad &lt;- open_dataset(\"https://data.source.coop/cboettig/pad-us-3/pad-us3-combined.parquet\")\n\npad_meta &lt;- duckdbfs::st_read_meta(\"https://data.source.coop/cboettig/pad-us-3/pad-us3-combined.fgb\", tblname = \"pad_meta\")\npad_meta\n\n# A tibble: 1 × 7\n  feature_count geom_column_name geom_type     name  code   wkt            proj4\n          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;chr&gt;\n1        440107 geom             Unknown (any) ESRI  102039 \"PROJCS[\\\"USA… +pro…\n\n\n\npad |&gt; \n  filter(State_Nm == \"CA\") |&gt; \n  group_by(FeatClass) |&gt; \n  summarise(total_area = sum(SHAPE_Area),\n            n = n()) |&gt;\n  collect()\n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n# A tibble: 5 × 3\n  FeatClass       total_area     n\n  &lt;chr&gt;                &lt;dbl&gt; &lt;dbl&gt;\n1 Proclamation 173843820097.   324\n2 Easement       7275244842. 11337\n3 Marine        36793465608.   214\n4 Designation  129887995064.  1293\n5 Fee          194547665576. 17873\n\n\n\nduckdbfs::load_spatial()\n\nReading in as a normal tibble, and then converting to a spatial object:\n\nca_fee &lt;- pad |&gt; \n  filter(State_Nm == \"CA\", FeatClass == \"Fee\") |&gt; \n  collect()\n\nca_fee |&gt; st_as_sf(sf_column_name = \"geometry\", crs = pad_meta$wkt)\n\nSimple feature collection with 17873 features and 34 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -2349024 ymin: 1242361 xmax: -1646723 ymax: 2452203\nProjected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version\n# A tibble: 17,873 × 35\n   FeatClass Category Own_Type Own_Name Loc_Own     Mang_Type Mang_Name Loc_Mang\n * &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   \n 1 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n 2 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n 3 Fee       Fee      STAT     OTHS     University… STAT      OTHS      Univers…\n 4 Fee       Fee      STAT     OTHS     University… STAT      OTHS      Univers…\n 5 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n 6 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n 7 Fee       Fee      LOC      CITY     City of Sa… LOC       CITY      City of…\n 8 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n 9 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n10 Fee       Fee      LOC      CITY     San Diego,… LOC       CITY      San Die…\n# ℹ 17,863 more rows\n# ℹ 27 more variables: Des_Tp &lt;chr&gt;, Loc_Ds &lt;chr&gt;, Unit_Nm &lt;chr&gt;, Loc_Nm &lt;chr&gt;,\n#   State_Nm &lt;chr&gt;, Agg_Src &lt;chr&gt;, GIS_Src &lt;chr&gt;, Src_Date &lt;chr&gt;,\n#   GIS_Acres &lt;int&gt;, Source_PAID &lt;chr&gt;, WDPA_Cd &lt;int&gt;, Pub_Access &lt;chr&gt;,\n#   Access_Src &lt;chr&gt;, Access_Dt &lt;chr&gt;, GAP_Sts &lt;chr&gt;, GAPCdSrc &lt;chr&gt;,\n#   GAPCdDt &lt;chr&gt;, IUCN_Cat &lt;chr&gt;, IUCNCtSrc &lt;chr&gt;, IUCNCtDt &lt;chr&gt;,\n#   Date_Est &lt;chr&gt;, Comments &lt;chr&gt;, EsmtHldr &lt;chr&gt;, EHoldTyp &lt;chr&gt;, …\n\n\nSimilarly, any normal data frame can be coerced to a spatial sf object, e.g.:\n\ndata.frame(lon = c(1,2), lat=c(0,0)) |&gt; st_as_sf(coords = c(\"lon\", \"lat\"), crs=4326)\n\nSimple feature collection with 2 features and 0 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1 ymin: 0 xmax: 2 ymax: 0\nGeodetic CRS:  WGS 84\n     geometry\n1 POINT (1 0)\n2 POINT (2 0)\n\n\n\nspatial_ex &lt;- paste0(\"https://raw.githubusercontent.com/cboettig/duckdbfs/\",\n                     \"main/inst/extdata/spatial-test.csv\") |&gt;\n  open_dataset(format = \"csv\") \n\nspatial_ex |&gt;\n  mutate(geometry = st_point(longitude, latitude)) |&gt;\n  to_sf(crs = 4326)\n\nSimple feature collection with 10 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1 ymin: 1 xmax: 10 ymax: 10\nGeodetic CRS:  WGS 84\n   site latitude longitude          geom\n1     a        1         1   POINT (1 1)\n2     b        2         2   POINT (2 2)\n3     c        3         3   POINT (3 3)\n4     d        4         4   POINT (4 4)\n5     e        5         5   POINT (5 5)\n6     f        6         6   POINT (6 6)\n7     g        7         7   POINT (7 7)\n8     h        8         8   POINT (8 8)\n9     i        9         9   POINT (9 9)\n10    j       10        10 POINT (10 10)\n\n\n\nca_fee &lt;- pad |&gt; \n  filter(State_Nm == \"CA\", FeatClass == \"Fee\") |&gt; \n  group_by(Own_Type) |&gt;\n  summarise(total = sum(SHAPE_Area)) |&gt; head(1000) |&gt; collect()"
  },
  {
    "objectID": "tutorials/example-4.html",
    "href": "tutorials/example-4.html",
    "title": "4: Biodiversity Intactness Index",
    "section": "",
    "text": "library(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap)\nlibrary(dplyr)\n\n\nlibrary(spData)\n\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\n\nbox_ca &lt;- spData::us_states |&gt; filter(NAME==\"California\") |&gt; st_bbox()\n\n\nbox &lt;- c(xmin=-123, ymin=37, xmax=-121, ymax=39) \nbox &lt;- c(box_ca)\nitems &lt;-  \n  stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\")  |&gt;\n  stac_search(collections = \"io-biodiversity\",\n              bbox = box,\n              limit = 100)  |&gt;\n  post_request() |&gt;\n  items_sign(sign_planetary_computer())\n\n\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"data\"))\n\nWarning in stac_image_collection(items$features, asset_names = c(\"data\")): STAC\nasset with name 'data' does not include eo:bands metadata and will be\nconsidered as a single band source\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = \"2017-01-01\", t1 = \"2017-12-31\",\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.005, dy = 0.005, dt = \"P1Y\")\n\ndata &lt;-  raster_cube(col, cube)\n\n\nbii &lt;- data |&gt; slice_time(\"2017-01-01\") |&gt;  st_as_stars()\ntm_shape(bii) + tm_raster()\n\nstars object downsampled to 1028 by 948 cells.\n\n\nWarning in value[[3L]](cond): could not rename the data.table"
  },
  {
    "objectID": "tutorials/example-2.html",
    "href": "tutorials/example-2.html",
    "title": "2: Adding Polygons",
    "section": "",
    "text": "library(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap)\nlibrary(dplyr)\nWe read in a spatial vector dataset with polygons using the Virtual Filesystem Interface (VSI) feature:\nurl &lt;- \"/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/mappinginequality.json\" \n\nredlines &lt;- \n  url |&gt;\n  st_read() |&gt;\n  st_make_valid() |&gt; \n  filter(st_is_valid(geometry))\n\nReading layer `mappinginequality' from data source \n  `/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/mappinginequality.json' \n  using driver `GeoJSON'\nSimple feature collection with 10154 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -122.7675 ymin: 25.70537 xmax: -69.60044 ymax: 48.2473\nGeodetic CRS:  WGS 84\nIn sf package, vector data looks almost like a normal tibble (data.frame), but with a special column (usually called “geom” or “geometry”). We can do the usual dplyr operations on the columns, e.g. to select just the redlining polygons in SF:\nsf_redlines &lt;- redlines |&gt; filter(city == \"San Francisco\")\nWe can use this as our bounding box from example 1:\nbox &lt;- st_bbox(sf_redlines)\n\nstart_date &lt;- \"2022-06-01\"\nend_date &lt;- \"2022-08-01\"\n\nitems &lt;-\n  stac(\"https://earth-search.aws.element84.com/v0/\") |&gt;\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = c(box),\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              limit = 100) |&gt;\n  ext_query(\"eo:cloud_cover\" &lt; 20) |&gt;\n  post_request()\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"B08\", \"B04\", \"SCL\"))\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.0001, dy = 0.0001, dt = \"P1D\",\n                  aggregation = \"median\", resampling = \"average\")\n\nmask &lt;- image_mask(\"SCL\", values=c(3, 8, 9)) # mask clouds and cloud shadows\n\ndata &lt;-  raster_cube(col, cube, mask = mask)\nndvi &lt;- data |&gt;\n  select_bands(c(\"B04\", \"B08\")) |&gt;\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |&gt;\n  reduce_time(c(\"mean(NDVI)\"))\nndvi_stars &lt;- st_as_stars(ndvi)\nmako &lt;- tm_scale_continuous(values = viridisLite::mako(30))\nfill &lt;- tm_scale_continuous(values = \"Greens\")\n\ntm_shape(ndvi_stars) + tm_raster(col.scale = mako) + \n  tm_shape(sf_redlines) + tm_borders(\"grade\", lwd=2)"
  },
  {
    "objectID": "tutorials/example-2.html#interactive-maps",
    "href": "tutorials/example-2.html#interactive-maps",
    "title": "2: Adding Polygons",
    "section": "Interactive maps",
    "text": "Interactive maps\ntmap_mode(\"view\")\ntmap mode set to 'view'\ntm_shape(ndvi_stars) + tm_raster(col.scale = mako) + \n  tm_shape(sf_redlines) + tm_borders(\"grade\", lwd=2)"
  },
  {
    "objectID": "tutorials/example-1.html",
    "href": "tutorials/example-1.html",
    "title": "1: Satellite data",
    "section": "",
    "text": "library(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap)\nlibrary(dplyr)\nearthdatalogin::gdal_cloud_config()\ngdalcubes::gdalcubes_options(parallel = TRUE)\n\n\nbox &lt;- c(xmin=-123, ymin=37, xmax=-121, ymax=39) \nstart_date &lt;- \"2022-06-01\"\nend_date &lt;- \"2022-08-01\"\nitems &lt;-\n  stac(\"https://earth-search.aws.element84.com/v0/\") |&gt;\n  stac_search(collections = \"sentinel-s2-l2a-cogs\",\n              bbox = box,\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              limit = 100) |&gt;\n  ext_query(\"eo:cloud_cover\" &lt; 20) |&gt;\n  post_request()\n\n\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"B08\", \"B04\", \"SCL\"))\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B08\", : STAC\nasset with name 'SCL' does not include eo:bands metadata and will be considered\nas a single band source\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.001, dy = 0.001, dt = \"P1M\",\n                  aggregation = \"median\", resampling = \"average\")\n\nThe SCL data layer in Sentinel is one of three ‘quality assurance’ layers provided in this data catalog. Table 3 in this description of the Sentinel-2 Level2A Specifications summarizes the classification codes (Cloud shadows, medium probability cloud, high probability cloud). An image mask basically drops these bad pixels.\n\nmask &lt;- image_mask(\"SCL\", values=c(3, 8, 9)) # mask clouds and cloud shadows\n\ndata &lt;-  raster_cube(col, cube, mask = mask)\n\n\nndvi &lt;- data |&gt;\n  select_bands(c(\"B04\", \"B08\")) |&gt;\n  apply_pixel(\"(B08-B04)/(B08+B04)\", \"NDVI\") |&gt;\n  reduce_time(c(\"mean(NDVI)\")) \n\n\nndvi_stars &lt;- st_as_stars(ndvi)\n\n\nmako &lt;- tm_scale_continuous(values = viridisLite::mako(30))\nfill &lt;- tm_scale_continuous(values = \"Greens\")\n\ntm_shape(ndvi_stars) + tm_raster(col.scale = mako)\n\nstars object downsampled to 1000 by 1000 cells.\n\n\nWarning in value[[3L]](cond): could not rename the data.table"
  },
  {
    "objectID": "tutorials/example-3.html",
    "href": "tutorials/example-3.html",
    "title": "3: animations",
    "section": "",
    "text": "Following the same template, but we compute over a larger bounding box and generate an animation\n\nlibrary(rstac)\nlibrary(gdalcubes)\nlibrary(stars)\nlibrary(tmap)\nlibrary(dplyr)\nearthdatalogin::gdal_cloud_config()\nearthdatalogin::with_gdalcubes()\n\n\nbox &lt;- c(xmin=-123, ymin=37, xmax=-122, ymax=38) \nstart_date &lt;- \"2022-01-01\"\nend_date &lt;- \"2022-06-30\"\nitems &lt;-\n  stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt;\n  stac_search(collections = \"sentinel-2-l2a\",\n              bbox = box,\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              limit = 1000) |&gt;\n  ext_query(\"eo:cloud_cover\" &lt; 20) |&gt;\n  post_request() |&gt;\n  items_sign(sign_planetary_computer())\n\nLet’s do a true-color RGB image this time by combining data from Blue, Green, and Red bands:\n\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"B02\", \"B03\", \"B04\", \"SCL\"))\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'SCL' does not include eo:bands metadata and will be considered\nas a single band source\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.001, dy = 0.001, dt = \"P1M\")\n\ndata &lt;-  raster_cube(col, cube)\n\n\nndvi &lt;- data |&gt;\n  select_bands(c(\"B02\",\"B03\", \"B04\")) |&gt;\n  write_ncdf(\"visual.nc\", overwrite=TRUE)\n\nWhile we could go directly from apply_pixel to animate, here we show how to stash a copy of the computed, rescaled and reprojected data as a local netcdf file that can be used in any further analysis without going back to the original data. To continue our gdalcubes pipeline, we can easily load this space-time ncdf cube and continue as before:\n\nncdf_cube(\"visual.nc\") |&gt;\n animate(rgb=3:1, \n         col = viridisLite::mako, fps=2, \n         save_as=\"visual.gif\")\n\n[1] \"visual.gif\""
  },
  {
    "objectID": "tutorials/example-5-fire.html",
    "href": "tutorials/example-5-fire.html",
    "title": "5: Fire Severity using Normalized Burn Index",
    "section": "",
    "text": "library(sf)\nlibrary(stars)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(rstac)\nlibrary(gdalcubes)\nurl &lt;- \"https://34c031f8-c9fd-4018-8c5a-4159cdff6b0d-cdn-endpoint.azureedge.net/-/media/calfire-website/what-we-do/fire-resource-assessment-program---frap/gis-data/april-2023/fire221gdb.zip?rev=9e3e1e5e61e242d5b2994d666d72a91a&hash=F424990CD64BB7C4CF01C6CE211C0A59\"\ndownload.file(url, \"fire221.gdb.zip\",  mode=\"wb\")\n\n\n\nunzip(\"fire221.gdb.zip\")\nfire_polys &lt;- \n  read_sf(\"fire22_1.gdb\", layer = \"firep22_1\") |&gt; \n  filter(st_is_valid(Shape))\njtree &lt;- \n  read_sf(\"/vsicurl/https://huggingface.co/datasets/cboettig/biodiversity/resolve/main/data/NPS.gdb\") |&gt; \n  filter(UNIT_NAME == \"Joshua Tree National Park\") |&gt; \n  st_transform(st_crs(fire_polys))\nfire_is_in_jtree &lt;- st_intersects(fire_polys, jtree, sparse=FALSE)\nfire_jtree &lt;- fire_polys |&gt; filter(fire_is_in_jtree)\n\nWarning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0.\nℹ Please use one dimensional logical vectors instead.\ntmap_mode(\"view\")\n\ntmap mode set to 'view'\n\ntm_shape(jtree) + tm_polygons() + \n tm_shape(fire_jtree) + tm_polygons(\"YEAR_\")\nBecause burned vegetation presents a very different spectral pattern to normal vegetation, burn intensity can be measured by comparing the spectra in different bands. The greatest contrast between burned and health vegetation can be seen in the NIR and SWIR bands, as seen in this typical spectral response curve:\nThe normalized burn ratio (NBR) is defined as the ratio:\n\\[ NBR = \\frac{NIR - SWIR}{NIR + SWIR}\\]"
  },
  {
    "objectID": "tutorials/example-5-fire.html#landsat-example",
    "href": "tutorials/example-5-fire.html#landsat-example",
    "title": "5: Fire Severity using Normalized Burn Index",
    "section": "Landsat example",
    "text": "Landsat example"
  },
  {
    "objectID": "tutorials/example-5-fire.html#sentinel-2-example",
    "href": "tutorials/example-5-fire.html#sentinel-2-example",
    "title": "5: Fire Severity using Normalized Burn Index",
    "section": "Sentinel-2 Example",
    "text": "Sentinel-2 Example\n\nbig_fire &lt;- fire_jtree |&gt; \n  filter(YEAR_ &gt; \"2015\") |&gt; \n  filter(Shape_Area == max(Shape_Area)) \n\n\nbox &lt;- big_fire |&gt; st_transform(4326) |&gt; st_bbox() \nalarm_date &lt;- big_fire$ALARM_DATE\n\n\nstart_date &lt;- as.character( alarm_date - days(5) )\nend_date &lt;- as.character( alarm_date + days(5) )\n\nitems &lt;-  \n  stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\")  |&gt;\n  stac_search(collections = \"sentinel-2-l2a\",\n              datetime = paste(start_date, end_date, sep=\"/\"),\n              bbox = c(box))  |&gt;\n  post_request() |&gt;\n  items_sign(sign_planetary_computer())\n\n\ncol &lt;- stac_image_collection(items$features, asset_names = c(\"B08\", \"B12\", \"SCL\"))\n\ncube &lt;- cube_view(srs =\"EPSG:4326\",\n                  extent = list(t0 = start_date, t1 = end_date,\n                                left = box[1], right = box[3],\n                                top = box[4], bottom = box[2]),\n                  dx = 0.0001, dy = 0.0001, dt = \"P1D\")\n\nmask &lt;- image_mask(\"SCL\", values=c(3, 8, 9)) # mask clouds and cloud shadows\ndata &lt;-  raster_cube(col, cube, mask = mask)\n\n\nnbr &lt;- data |&gt; \n  apply_pixel(\"(B08-B12)/(B08+B12)\", \"NBR\") \n\nbefore_fire &lt;- nbr |&gt; slice_time(\"2022-05-25\") \nafter_fire &lt;- nbr  |&gt; slice_time(\"2022-05-30\")\n\n\nbefore_fire |&gt; plot()\n\n\n\n\n\nafter_fire |&gt; plot()\n\n\n\n\n\nafter_fire_stars &lt;- after_fire |&gt; st_as_stars()\n\nWarning in CPL_read_gdal(as.character(x), as.character(options),\nas.character(driver), : GDAL Message 1: The dataset has several variables that\ncould be identified as vector fields, but not all share the same primary\ndimension. Consequently they will be ignored.\n\nbefore_fire_stars &lt;- before_fire |&gt; st_as_stars()\n\nWarning in CPL_read_gdal(as.character(x), as.character(options),\nas.character(driver), : GDAL Message 1: The dataset has several variables that\ncould be identified as vector fields, but not all share the same primary\ndimension. Consequently they will be ignored.\n\nst_dimensions(before_fire_stars) &lt;- st_dimensions(after_fire_stars)\n\ndnbr &lt;- before_fire_stars - after_fire_stars\n\n\ntmap_mode(\"view\")\n\ntmap mode set to 'view'\n\ntm_shape(dnbr) + tm_raster() +\ntm_shape(big_fire) + tm_borders() \n\nVariable(s) \"col\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "tutorials/example-5-fire.html#with-slider",
    "href": "tutorials/example-5-fire.html#with-slider",
    "title": "5: Fire Severity using Normalized Burn Index",
    "section": "with slider",
    "text": "with slider\nWe can use leaflet to create a slider bar. This is more verbose than tmap but very powerful. (Note that this example requires the GitHub)\n\nlibrary(leaflet.extras2)\n\nLoading required package: leaflet\n\nlibrary(terra) # leaflet doesn't know about the stars package yet\n\nterra 1.7.71\n\n\n\nAttaching package: 'terra'\n\n\nThe following objects are masked from 'package:gdalcubes':\n\n    animate, crop, size\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n    Map &lt;- leaflet() |&gt; \n      addMapPane(\"right\", zIndex = 0) |&gt; \n      addMapPane(\"left\",  zIndex = 0) |&gt;\n      addTiles(group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) |&gt; \n      addTiles(group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) |&gt; \n      addRasterImage(x = rast(after_fire_stars), options = leafletOptions(pane = \"right\"), group = \"r1\") |&gt; \n      addRasterImage(x = rast(before_fire_stars), options = leafletOptions(pane = \"left\"), group = \"r2\") |&gt; \n      addLayersControl(overlayGroups = c(\"r1\", \"r2\")) |&gt;  \n      addSidebyside(layerId = \"sidecontrols\",\n                    rightId = \"baseid1\",\n                    leftId  = \"baseid2\")\n    \n\n\nMap"
  },
  {
    "objectID": "tutorials/gbif-python.html",
    "href": "tutorials/gbif-python.html",
    "title": "7. gbif-python",
    "section": "",
    "text": "%pip install pydeck\n\nCollecting pydeck\n  Using cached pydeck-0.8.0-py2.py3-none-any.whl.metadata (3.9 kB)\nCollecting jinja2&gt;=2.10.1 (from pydeck)\n  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\nCollecting numpy&gt;=1.16.4 (from pydeck)\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 1.1 MB/s eta 0:00:00a 0:00:01\nCollecting MarkupSafe&gt;=2.0 (from jinja2&gt;=2.10.1-&gt;pydeck)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nUsing cached pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\nDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 3.7 MB/s eta 0:00:00\nDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 45.3 MB/s eta 0:00:00:00:0100:01\nDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nInstalling collected packages: numpy, MarkupSafe, jinja2, pydeck\nSuccessfully installed MarkupSafe-2.1.5 jinja2-3.1.3 numpy-1.26.4 pydeck-0.8.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# Define a layer to display on a map\nDATA = 'https://minio.carlboettiger.info/shared-data/mammalia_occ_gb.csv'\nimport pydeck as pdk\n \nlayer = pdk.Layer(\n    \"HexagonLayer\",\n    DATA,\n    get_position=['lng', 'lat'],\n    elevation_scale=100,\n  #  elevation_range=[0, 1000],\n    get_fill_color = [\"elevation\", \"0\", \"elevation\", 140],\n    extruded=True,\n    radius=1000,\n    auto_highlight=True,\n    pickable=True,\n    lower_percentile=0.8,\n    alpha=0.8\n)\n\n# Set the viewport location\nview_state = pdk.ViewState(\n    longitude=-1.415,\n    latitude=52.2323,\n    zoom=4,\n    min_zoom=1,\n    max_zoom=12,\n    pitch=40.5,\n    bearing=-27.36)\n\n# Render\nr = pdk.Deck(layers=[layer], initial_view_state=view_state)\nr.to_html(\"hex_layer.html\")"
  }
]